Конспект по многопоточности C++ (по cppreference.com, стандарту C++20 и книге Э. Уильемса «Практика многопоточного программирования»).

## Потоки

**Поток выполнения** (или *тред*, от англ. *thread* — нить) — это наименьшая единица выполнения программы, которой может управлять операционная система. Потоки позволяют выполнять несколько задач параллельно внутри одного процесса.

В стандартной библиотеке C++ потоки представлены двумя классами:

* `std::thread`
* `std::jthread`

При создании потока в `std::thread` и `std::jthread` аргументы функции копируются в локальное хранилище потока и передаются вызываемому объекту как r-value. Это значит, что параметры функции передаются по значению — копированием или перемещением.
Если необходимо передать аргумент по ссылке, его нужно обернуть с помощью `std::ref` или `std::cref`.

Любое значение, возвращаемое функцией потока, игнорируется. Если потоковая функция выбрасывает исключение, вызывается `std::terminate`.

Класс `std::jthread` в отличие от `std::thread`:

* автоматически вызывает `join()` в деструкторе, если тот не был вызван явно;
* поддерживает механизм остановки потока с помощью `std::stop_token`. (см. примеры в threads)

Функции для управления текущим потоком (`std::this_thread`):

* `std::this_thread::yield()` — даёт подсказку планировщику, позволяя другим потокам выполняться;
* `std::this_thread::get_id()` — возвращает идентификатор текущего потока;
* `std::this_thread::sleep_for()` — приостанавливает выполнение текущего потока как минимум на заданный промежуток времени;
* `std::this_thread::sleep_until()` — приостанавливает выполнение потока до наступления указанного момента времени.

## Мьютексы

Мьютекс в C++ (англ. *mutex*, от *mutual exclusion* — «взаимное исключение») — базовый механизм синхронизации. Он предназначен для организации взаимоисключающего доступа к общим данным из нескольких потоков с использованием барьеров памяти.

Существуют следующие основные разновидности мьютексов в C++:

- `std::mutex` — базовая реализация, обеспечивающая единственный уровень блокировки: только один поток может захватить мьютекс в данный момент времени.
- `std::recursive_mutex` — позволяет одному и тому же потоку многократно захватывать мьютекс. Это полезно в случаях, когда функция, уже захватившая мьютекс, вызывает другую функцию, которая также пытается его захватить.
- `std::shared_mutex` — поддерживает два типа захвата:  
  - **эксклюзивный** (только один поток может владеть блокировкой);  
  - **разделяемый** (несколько потоков могут одновременно владеть разделяемой блокировкой, но при этом исключается любая эксклюзивная блокировка).  

Разделяемая блокировка эффективна в сценариях, где большинство операций — чтение, а записи редки: несколько потоков могут параллельно читать данные, а при необходимости записи один поток получает эксклюзивную блокировку, временно блокируя все остальные.

### Мьютексы с таймаутом

Каждый из перечисленных типов мьютексов имеет аналоги с поддержкой попытки захвата блокировки по таймеру. Например, **`std::timed_mutex`** предоставляет дополнительный интерфейс:
- `try_lock_for` — пытается захватить мьютекс на заданном промежутке времени;
- `try_lock_until` — пытается захватить мьютекс до указанного момента времени.

### Менеджеры мьютексов

* **`std::lock_guard`** — простая RAII-оболочка над мьютексом, автоматически захватывающая его при создании и освобождающая при выходе из области видимости. Предназначена для кратковременного владения мьютексом без возможности управления блокировкой вручную.

* **`std::scoped_lock`** — универсальный RAII-менеджер, который может одновременно захватывать несколько мьютексов безопасным способом, предотвращая взаимную блокировку. Может использоваться и с одним мьютексом.

* **`std::unique_lock`** — гибкий RAII-менеджер, предоставляющий расширенный интерфейс для управления мьютексом: можно откладывать захват (`defer_lock`), временно освобождать (`unlock`), повторно захватывать (`lock`), а также передавать владение между функциями (поддерживает перемещение).

* **`std::shared_lock`** — RAII-оболочка для разделяемой блокировки (`std::shared_mutex`), позволяющая нескольким потокам одновременно читать данные, но блокирующая доступ на запись при активных читателях.

#### Типы стратегий захвата (теги для конструкторов менеджеров)

* **`std::defer_lock_t`** — не захватывать мьютекс при создании блокировки (захват выполняется позже вручную).
* **`std::try_to_lock_t`** — попытаться захватить мьютекс без ожидания (если занят — не блокироваться).
* **`std::adopt_lock_t`** — использовать уже захваченный ранее мьютекс (предполагается, что поток уже владеет им).

### Condition variables (условные переменные)

Условная переменная — это синхронизирующий примитив, который позволяет потокам ждать наступления определённого события.

- `std::condition_variable` — класс, работающий только с std::unique_lock< std::mutex >.
- `std::condition_variable_any` — Более гибкая версия, работает с любым типом блокировки, а не только с std::unique_lock< std::mutex >. Поддерживает механизм остановки ожидания с помощью `std::stop_token`.
- `std::notify_all_at_thread_exit` — Специальная функция, позволяющая уведомить ожидающие потоки,
когда текущий поток полностью завершится (включая деструкторы thread-local переменных).
- `std::cv_status`— Перечисление, описывающее результат ожидания с таймаутом:

## Симафоры, защёлки, барьеры.
- `std::counting_semaphore` — семафор, ограничивающий количество одновременно выполняющихся потоков.

- `std::binary_semaphore` — частный случай счётного семафора (значения 0/1), аналог мьютекса.

- `std::latch` — одноразовый барьер синхронизации: поток(и) ждут, пока счётчик не достигнет нуля.

- `std::barrier` — многоразовый барьер: позволяет группе потоков синхронизироваться на нескольких этапах выполнения.

## Фьючерсы и асинхронные операции

Фьючерсы — это средства синхронизации, которые позволяют получить результат асинхронной операции, когда он станет доступен.
Основные механизмы в стандартной библиотеке C++:

* `std::promise`
* `std::future`
* `std::shared_future`
* `std::async`
* `std::packaged_task`

### `std::promise` и `std::future`

Эти классы используются вместе:

* **`std::promise`** — объект, в который один поток *помещает результат* вычислений;
* **`std::future`** — объект, из которого *другой поток получает результат*.

Между ними создаётся канал передачи данных «один к одному»: результат или исключение, помещённое в `promise`, становится доступным через `future`.

Если поток, владеющий `std::promise`, выбросит исключение и вызовет `set_exception()`, то вызов `get()` в `future` пробросит это исключение.

### `std::shared_future`

* Аналог `std::future`, но допускает **множественное чтение результата из разных потоков**.
* Создаётся либо напрямую, либо путём вызова `.share()` у `std::future`.

### `std::packaged_task` Позволяет *обернуть функцию* в асинхронную задачу, к которой можно получить `future`.
Часто используется для создания пула потоков или явного управления асинхронными задачами.

### `std::async`

Функция-обёртка, которая **запускает функцию асинхронно** и возвращает `std::future`, с помощью которого можно получить результат.

Режимы запуска:

* `std::launch::async` — запускает функцию в новом потоке;
* `std::launch::deferred` — выполняет функцию *только при вызове `get()` или `wait()`*;
* комбинация `std::launch::async | std::launch::deferred` — реализация сама выбирает поведение.

### Поведение `get()` и `wait()`

* `get()` — блокируется до готовности результата, возвращает значение или выбрасывает исключение.
* `wait()` — ожидает готовности результата, но не извлекает его.
* После вызова `get()` значение можно получить **только один раз** (у `shared_future` — многократно).

## Атомики

### Модель памяти

Все данные в программах на C++ состоят из **объектов**.
Объект в стандарте C++ определяется как **область хранения**, которой сопоставлены такие свойства, как тип, время жизни и границы допустимых операций.

Некоторые объекты, например `int` или `float`, представляют собой простые значения элементарных типов. Другие — экземпляры пользовательских классов.
Некоторые объекты (массивы, экземпляры производных классов, классы с нестатическими полями) содержат **подобъекты**, а некоторые — нет.

---

Каждый объект любого типа занимает **одну или несколько областей памяти**.
Область памяти — это либо отдельный объект (или подобъект) скалярного типа, например `unsigned short` или `my_class*`, либо последовательность смежных битовых полей.

> Важно: хотя каждое битовое поле является отдельным объектом, **смежные битовые поля считаются частью одной области памяти**.

---

#### Пример

Предположим, у нас есть следующая структура:

```cpp
struct Data {
    unsigned bf1 : 3;
    unsigned bf2 : 5;
    std::string s;
    int i;
    unsigned bf3 : 0;  // безымянное битовое поле нулевой длины
    unsigned bf4 : 8;
};
```

* Вся структура `Data` — это **один объект**, состоящий из нескольких подобъектов.
* Битовые поля `bf1` и `bf2` разделяют одну и ту же область памяти.
* Объект `std::string s` состоит из нескольких внутренних областей памяти.
* Поля `i` и `bf4` имеют собственные области памяти.
* Безымянное битовое поле нулевой длины (`bf3`) **разрывает общую область**, начиная новую область памяти для `bf4`, но само своей области не имеет.

---

#### Основные выводы

1. Каждая переменная — это объект, включая переменные, являющиеся компонентами других объектов.
2. Каждый объект занимает как минимум **одну область памяти**.
3. Переменные элементарных типов (`int`, `char` и т. п.) всегда занимают ровно одну область памяти, независимо от размера и расположения (даже внутри массива).
4. Смежные битовые поля принадлежат **одной и той же области памяти**.

---

Эти понятия напрямую связаны с **конкурентным программированием**, так как операции с разделяемыми данными должны учитывать границы объектов и областей памяти.
Например, стандарт C++ определяет понятие **data race** — состояния, при котором два потока одновременно обращаются к одной и той же области памяти без должной синхронизации.

### Перевод 6.9.2.1 стандрта С++. Data races.

1. Значение объекта, **видимое потоку** *T* в определённый момент времени, может быть:

* **начальным значением** объекта,
* **значением, присвоенным этому объекту самим потоком T**,
* или **значением, присвоенным этому объекту другим потоком**,
  в соответствии с приведёнными ниже правилами.

> **Примечание:**
> В некоторых случаях вместо этого может иметь место **неопределённое поведение**.
> Большая часть данного подпункта направлена на поддержку **атомарных операций** с **явно заданными и детализированными ограничениями видимости**.
> Однако он также **неявно поддерживает более простую модель** для менее сложных программ.

---

2. Два вычисления выражений **находятся в конфликте**, если одно из них **модифицирует область памяти**, а другое **читает или модифицирует ту же самую область памяти**.

---

3. Библиотека определяет ряд **атомарных операций** и **операций с мьютексами**, которые специально обозначены как **синхронизационные операции**.
Эти операции играют особую роль — они обеспечивают видимость изменений, выполненных в одном потоке, для других потоков.

Синхронизационная операция, связанная с одной или несколькими областями памяти, может быть:

* **consume-операцией**,
* **acquire-операцией**,
* **release-операцией**,
* или одновременно **acquire и release**-операцией.

Синхронизационная операция, не связанная с конкретной областью памяти, называется **барьером (fence)** и может быть:

* **acquire-barrier**,
* **release-barrier**,
* или одновременно **acquire и release-barrier**.

Кроме того, существуют **«ослабленные» атомарные операции (relaxed)**, которые **не являются синхронизационными**, и **атомарные операции чтения-модификации-записи (read-modify-write)**, обладающие особыми свойствами.

> **Примечание:**
> Например, вызов, который **захватывает мьютекс**, выполняет **acquire-операцию** над памятью, соответствующей этому мьютексу.
> Соответственно, вызов, который **освобождает тот же мьютекс**, выполняет **release-операцию** над этими же участками памяти.
>
> В неформальном смысле, **release-операция** над объектом *A* заставляет все предыдущие побочные эффекты (записи в память) стать **видимыми для других потоков**, которые позднее выполняют **consume**- или **acquire-операции** над тем же объектом *A*.
>
> «Ослабленные» (“Relaxed”) атомарные операции хоть и **не являются синхронизационными**, но **не могут привести к состоянию гонки данных (data race)**.

---

4. Все модификации конкретного **атомарного объекта** *M* происходят в определённом **полном порядке**, называемом **порядком модификаций объекта M (modification order)**.

> **Примечание:** Для каждого атомарного объекта существует **собственный порядок модификаций**. Нет требования объединять их в один общий порядок для всех объектов. В общем случае это **невозможно**, так как разные потоки могут наблюдать модификации разных объектов в **несогласованных порядках**.

---

5. **Последовательность release-операций** (*release sequence*), начинающаяся с release-операции *A* на атомарном объекте *M*, — это **максимальная непрерывная подпоследовательность побочных эффектов** в порядке модификаций объекта *M*, где:

* **первая операция — A**,
* **каждая последующая операция** — атомарная операция чтения-модификации-записи (read-modify-write).

---

6. Некоторые вызовы библиотечных функций **синхронизируются с** (*synchronize with*) другими вызовами, выполняемыми в другом потоке.
   Например, **атомарное store-release** синхронизируется с **load-acquire**, которое читает значение, записанное этим store.

> **Примечания:**
>
> * За исключением указанных случаев, чтение более позднего значения **не гарантирует его видимость** в других потоках. Такое требование иногда мешало бы эффективной реализации.
> * Спецификации синхронизационных операций определяют, когда одно чтение получает значение, записанное другой операцией.
> * Для атомарных объектов это определено однозначно.
> * Все операции с данным мьютексом выполняются в **едином полном порядке**.
> * Каждое захватывание мьютекса «читает значение», записанное последним освобождением того же мьютекса.

---

7. **Вычисление A несёт зависимость (carries a dependency) к вычислению B**, если выполняется одно из условий:

   7.1. Значение A используется как операнд для B, **за исключением случаев**:

      7.1.1. B является вызовом любой специализации `std::kill_dependency`  
      7.1.2. A является левым операндом встроенного логического AND (`&&`) или OR (`||`)  
      7.1.3. A является левым операндом тернарного оператора (`?:`)  
      7.1.4. A является левым операндом встроенного оператора запятой (`,`)  

   7.2. _A_ записывает скалярный объект или битовое поле _M_, а _B_ читает значение, записанное _A_ в _M_, при том что **A упорядочено перед (sequenced before) B**.

   7.3. Существует вычисление _X_, такое что **A несёт зависимость к X**, а _X_ несёт зависимость к _B_.

> **Примечание:**
> “Несёт зависимость к” — это подмножество отношений “упорядочено перед” (`sequenced before`) и также строго **внутрипотоковое**.

```cpp
/// 7.1: Значение A используется как операнд для B
int a1 = 5;         // вычисление A
int b1 = a1 + 2;    // вычисление B (A → B)

/// 7.2: A записывает объект, B читает его значение, A упорядочено перед B
int x = 0;           // объект x
x = 42;              // вычисление A: запись в x
int y = x;           // вычисление B: чтение x (A → B)

/// 7.3: Транзитивная зависимость через X
int a2 = 1;          // вычисление A
int x2 = a2 + 1;     // вычисление X (A → X)
int b2 = x2 * 2;     // вычисление B (X → B), транзитивно: A → B

```
---

8. **Вычисление A упорядочено по зависимости перед вычислением B** (*dependency-ordered before*), если выполняется одно из условий:

  8.1. *A* выполняет **release-операцию** над атомарным объектом *M*, а в другом потоке *B* выполняет **consume-операцию** над *M* и читает значение, записанное *A*.

  8.2. Существует вычисление *X*, такое что **A dependency-ordered перед X**, а *X* несёт зависимость к *B*.

> **Примечание:**
> Отношение *dependency-ordered before* аналогично *synchronizes with*, но использует **release/consume** вместо **release/acquire**.

```cpp
#include <atomic>
#include <thread>
#include <cassert>

std::atomic<int> M{0};
int result = 0;

// 8.1: A выполняет release, B выполняет consume
void threadA() {
    M.store(42, std::memory_order_release); // A: release
}

void threadB() {
    int value = M.load(std::memory_order_consume); // B: consume
    result = value; // B "видит" значение, записанное A
}

// 8.2: цепочка зависимостей через X
int X = 0;

void threadA2() {
    M.store(100, std::memory_order_release); // A: release
}

void threadX() {
    X = M.load(std::memory_order_consume);   // X: consume
}

void threadB2() {
    result = X + 1; // B зависит от X
}

int main() {
    std::thread t1(threadA);
    std::thread t2(threadB);
    t1.join(); t2.join();
    assert(result == 42); // B "видит" значение от A

    std::thread ta(threadA2);
    std::thread tx(threadX);
    std::thread tb(threadB2);
    ta.join(); tx.join(); tb.join();
    assert(result == 101); // B учитывает зависимость через X
}
```

---

### 9. Межпотоковое упорядочивание вычислений (inter-thread happens before)

Вычисление **A inter-thread happens before B** (*A* «происходит до» *B* между потоками), если выполняется одно из условий:

  9.1. *A* **синхронизируется с** *B* (`synchronizes with`),
  
  9.2. *A* **dependency-ordered перед** *B* (`dependency-ordered before`),
  
  9.3. Существует вычисление *X*, такое что выполняется одно из:

   9.3.1. *A* **синхронизируется с** *X* и *X* **упорядочено перед** *B* (`sequenced before`),
   
   9.3.2. *A* **упорядочено перед** *X* и *X* **inter-thread happens before** *B*,
   
   9.3.3. *A* **inter-thread happens before** *X* и *X* **inter-thread happens before** *B*.

> **Примечание:**
> Отношение *inter-thread happens before* описывает произвольные комбинации отношений *sequenced before*, *synchronizes with* и *dependency-ordered before*, с двумя исключениями:
>
> 1. Комбинация **не может заканчиваться** на *dependency-ordered before*, за которой следует *sequenced before*. Причина: consume-операция упорядочивает только те операции, на которые она реально влияет. Любая последующая release-операция обеспечит правильное упорядочивание для предыдущей consume-операции.
> 2. Комбинация **не может состоять полностью** из *sequenced before*. Это необходимо, чтобы обеспечить транзитивность *inter-thread happens before* и корректность общей модели «происходит до».

```cpp
std::atomic<int> M{0};
int x = 0;

// 9.1 A synchronizes with B
void thread1_sync() {
    M.store(42, std::memory_order_release); // A: release
}

void thread2_sync() {
    int v = M.load(std::memory_order_acquire); // B: acquire, synchronizes with A
    std::cout << "9.1: " << v << "\n"; // гарантированно видит 42
}

// 9.2 A dependency-ordered before B
std::atomic<int> N{0};

void thread1_dep() {
    N.store(10, std::memory_order_release); // A: release
}

void thread2_dep() {
    int val = N.load(std::memory_order_consume); // B: consume, dependency-ordered after A
    int result = val * 2; // использование значения val в вычислении B
    std::cout << "9.2: " << result << "\n"; // гарантированно 20
}


// 9.3 Использование X
// 9.3.1: A synchronizes with X и X sequenced before B
void thread1_X1() {
    M.store(5, std::memory_order_release); // A
}

void thread2_X1() {
    int tmp = M.load(std::memory_order_acquire); // X, A synchronizes with X
    x = tmp + 1; // B, X sequenced before B
    std::cout << "9.3.1: " << x << "\n"; // гарантированно видит 5+1=6
}

// 9.3.2: A sequenced before X, X inter-thread happens before B
void thread1_X2() {
    int local = 7; // A
    int tmp = local + 1; // X, A sequenced before X
    M.store(tmp, std::memory_order_release); // inter-thread happens before B
}

void thread2_X2() {
    int val = M.load(std::memory_order_acquire); // B
    std::cout << "9.3.2: " << val << "\n"; // гарантированно видит 8
}

// 9.3.3: A inter-thread happens before X, X inter-thread happens before B
void thread1_X3() {
    M.store(3, std::memory_order_release); // A
}

void thread2_X3() {
    int tmp = M.load(std::memory_order_acquire); // X, inter-thread happens before B
    x = tmp * 2; // B
    std::cout << "9.3.3: " << x << "\n"; // гарантированно видит 6
}

// примеры 9.1 и 9.2
std::thread t1(thread1_sync), t2(thread2_sync);
t1.join(); t2.join();
std::thread t3(thread1_dep), t4(thread2_dep);
t3.join(); t4.join();

// пример 9.3.1
std::thread t5(thread1_X1), t6(thread2_X1);
t5.join(); t6.join();

// пример 9.3.2
std::thread t7(thread1_X2), t8(thread2_X2);
t7.join(); t8.join();

// пример 9.3.3
std::thread t9(thread1_X3), t10(thread2_X3);
t9.join(); t10.join();
```

---

10. Вычисление **A происходят ранее B** (*happens before*) (или эквивалентно *B happens after A*) выполняется, если:

  10.1. *A* **упорядочено перед** *B* (`sequenced before`), или

  10.2. *A* **упорядочено происходит до** (*inter-thread happens before*) *B*.
  > Может включать: synchronizes with (release/acquire)
  > dependency-ordered before (release/consume)
  > комбинации этих отношений, с ограничениями (см. исключения 9.3).


> Реализация должна гарантировать, что никакое выполнение программы **не демонстрирует циклы** в отношении «happens before».
> *Примечание:* циклы возможны только через использование consume-операций.

```cpp
// 10.1. sequenced before
int a = 5;       // A
int b = a + 1;   // B, A sequenced before B
std::cout << b << "\n"; // видит 6

// 10.2 inter-thread happens before
std::atomic<int> M;

void thread1() {
    M.store(10, std::memory_order_release); // A: release
}

void thread2() {
    int val = M.load(std::memory_order_acquire); // B: acquire. А до В
    std::cout << "B видит: " << val << "\n"; // гарантированно видит 10
}

std::thread t1(thread1);
std::thread t2(thread2);
t1.join(); t2.join();
```

---

**Simply happens before**

11. Вычисление **A simply happens before B** выполняется, если:

1. A **упорядочено перед** B (`sequenced before`), или
2. A **синхронизируется с** B, или
3. Существует X, такое что A simply happens before X и X simply happens before B.

> **Примечание:**
> Если не использовать consume-операции, отношения *happens before* и *simply happens before* **идентичны**.

---

**12. Strongly happens before (Сильное «происходит до»)**

Вычисление **A strongly happens before D** выполняется, если выполняется одно из условий:

1. **A упорядочено перед D** (`sequenced before`), или
2. **A синхронизируется с D**, и при этом **A** и **D** — атомарные операции с последовательной согласованностью (`seq_cst`), или
3. Существуют вычисления **B** и **C**, такие что:

   * A упорядочено перед B (`sequenced before`),
   * B «просто происходит до» C (`simply happens before`),
   * C упорядочено перед D (`sequenced before`), или
4. Существует вычисление **B**, такое что:

   * A сильно происходит до B,
   * B сильно происходит до D.

> **Примечание:** Интуитивно, если A strongly happens before D, то A будет наблюдаться как предшествующее D во всех контекстах. Сильное «происходит до» не учитывает операции consume.

---

**13. Видимый сайд-эффект (Visible side effect)**

Сайд-эффект **A** на скалярном объекте или битовом поле **M** относительно вычисления значения **B** удовлетворяет условиям:

1. **A происходит до B** (`happens before`), и
2. **Нет другого сайд-эффекта X**, такого что A происходит до X, а X происходит до B.

Значение неатомарного скалярного объекта или битового поля M, определяемое вычислением B, **должно быть равно значению, записанному сайд-эффектом A**.

> **Примечание:** Если невозможно однозначно определить, какой сайд-эффект виден, поведение становится неопределённым.
> Это гарантирует, что операции над обычными объектами не будут видимо переупорядочены. На практике это сложно обнаружить без гонок данных, но это необходимо, чтобы правильно определять data races и поддерживать последовательную согласованность (`sequential consistency`) для атомарных операций.

---

**14. Значение атомарного объекта**
Значение атомарного объекта **M**, определяемое вычислением **B**, должно быть значением, записанным некоторым сайд-эффектом **A**, который модифицирует **M**, при этом **B** не происходит до **A** (`B does not happen before A`).

> **Примечание:** Множество таких сайд-эффектов ограничено остальными правилами в стандарте, особенно требованиями когерентности (coherence).

---

**15. Write-Write Coherence (Когерентность записи-записи)**
Если операция **A**, модифицирующая атомарный объект **M**, происходит до операции **B**, модифицирующей **M**, то **A** должна быть раньше **B** в порядке модификаций объекта **M** (`modification order`).

> **Примечание:** Это называется **write-write coherence**.

---

**16. Read-Read Coherence (Когерентность чтение-чтение)**
Если вычисление значения **A** атомарного объекта **M** происходит до вычисления значения **B** для того же объекта, и **A** получает своё значение от сайд-эффекта **X**, то **B** должно получить либо значение **X**, либо значение **Y**, где **Y** следует за **X** в порядке модификаций объекта.

> **Примечание:** Это называется **read-read coherence**.

---

**17. Read-Write Coherence (Когерентность чтение-запись)**
Если вычисление значения **A** атомарного объекта **M** происходит до операции **B**, которая модифицирует **M**, то **A** должно получить своё значение из сайд-эффекта **X**, который предшествует **B** в порядке модификаций объекта.

> **Примечание:** Это **read-write coherence**.

---

**18. Write-Read Coherence (Когерентность запись-чтение)**
Если сайд-эффект **X** на атомарном объекте **M** происходит до вычисления значения **B**, то **B** должно получить своё значение либо из **X**, либо из сайд-эффекта **Y**, который следует за **X** в порядке модификаций объекта.

> **Примечание:** Это **write-read coherence**.

---

**19. Примечание о компиляторе и аппаратной когерентности**
Эти четыре требования к когерентности фактически запрещают компилятору переупорядочивать атомарные операции для одного объекта, даже если обе операции — relaxed (`memory_order_relaxed`).
Это позволяет использовать гарантии когерентности кэша, предоставляемые большинством современных процессоров, для атомарных операций в C++.

---

**20. Примечание о значении атомарной загрузки**
Значение, которое наблюдает `load` атомарного объекта, зависит от отношения **“happens before”**, которое в свою очередь зависит от значений, наблюдаемых другими атомарными загрузками.
Идея такова: для каждой атомарной загрузки должна существовать связь с сайд-эффектами, которые она наблюдает. При правильном выборе порядка модификаций и отношений **happens before** это обеспечивает корректное поведение атомарных операций.

---

**21. Потенциально конкурентные действия (potentially concurrent actions)**
Два действия считаются потенциально конкурентными, если:

1. Они выполняются разными потоками, или
2. Они не упорядочены, по крайней мере одно выполняется обработчиком сигнала, и они не выполняются в рамках одного и того же вызова обработчика сигнала.

**Data race (гонка данных)** возникает, если программа содержит два потенциально конкурентных конфликта действий, при этом хотя бы одно из действий не атомарное, и ни одно из них не происходит до другого (`happens before`), кроме особого случая с обработчиками сигналов.

Любая такая гонка данных приводит к **неопределенному поведению (undefined behavior)**.

> **Примечание:** Программы, которые корректно используют мьютексы и атомарные операции с `memory_order::seq_cst` для предотвращения всех гонок данных и не используют других операций синхронизации, ведут себя так, как если бы операции их потоков просто чередовались последовательно. Каждое вычисление значения объекта берется из последнего сайд-эффекта на этом объекте. Это называется **sequential consistency (последовательная согласованность)**. Однако это применимо только к программам без гонок данных.

---

**22. Особый случай для `volatile std::sig_atomic_t`**
Два доступа к одному объекту типа `volatile std::sig_atomic_t` **не создают гонку данных**, если оба происходят в одном потоке, даже если один или оба происходят в обработчике сигнала.

Для каждого вызова обработчика сигнала вычисления потока можно разделить на две группы A и B:

* Никакие вычисления из группы B не происходят до вычислений из группы A.
* Значения объектов `volatile std::sig_atomic_t` воспринимаются так, как если бы все вычисления A произошли до запуска обработчика сигнала, а обработчик сигнала завершился до всех вычислений B.

---

**23. Ограничения на трансформации компилятора**
Компилятор не должен вводить присваивания в потенциально разделяемую память, если это не изменяет поведение абстрактной машины, так как такое присваивание может перезаписать значение, созданное другим потоком, создавая гонку данных.

Это включает, например, присваивание членам структуры, которое может перезаписать соседние члены, находящиеся в отдельных областях памяти.

Также запрещено переупорядочивание атомарных загрузок, если они могут пересекаться (alias), так как это может нарушить правила когерентности.

---

**24. Спекулятивное чтение**
Трансформации, которые вводят спекулятивное чтение потенциально разделяемой памяти, **могут нарушить семантику программы**, так как могут создать гонку данных.

Однако такие трансформации **допустимы** для оптимизирующих компиляторов, нацеленных на конкретное железо с предсказуемой обработкой гонок данных.
Для гипотетической машины, которая не терпит гонки или имеет аппаратное обнаружение гонок, такие трансформации были бы недопустимы.